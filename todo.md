# ğŸ“‹ Dolap Sale Prediction â€” Master TODO

> **Son gÃ¼ncelleme:** 2026-03-02
> **Branch:** `develop`
> **Durum:** Phase 3 tamamlandÄ± â†’ M1 Data Collection devam ediyor

---

## Proje HaritasÄ±

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DOLAP SALE PREDICTION â€” ROADMAP                      â”‚
â”‚                                                                         â”‚
â”‚  ğŸ—ï¸ M0 â€” FOUNDATION                                        [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] âœ…â”‚
â”‚  â”œâ”€â”€ Phase 0   â€” Project Architecture                                   â”‚
â”‚  â”œâ”€â”€ Phase 0.5 â€” ML Infrastructure (Experiment Tracking)                â”‚
â”‚  â””â”€â”€ Phase 1   â€” Literature Research & Project Report                   â”‚
â”‚                                                                         â”‚
â”‚  ğŸŒ M1 â€” DATA COLLECTION SYSTEM                            [â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘] ğŸ”„â”‚
â”‚  â”œâ”€â”€ Phase 2   â€” Dolap Site Reverse Engineering                         â”‚
â”‚  â”œâ”€â”€ Phase 3   â€” Basic Scraper Prototype                                â”‚
â”‚  â”œâ”€â”€ Phase 4   â€” Anti-Ban Protection                                    â”‚
â”‚  â””â”€â”€ Phase 5   â€” Snapshot Storage System                                â”‚
â”‚                                                                         â”‚
â”‚  â³ M2 â€” TEMPORAL LABELING SYSTEM                           [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] â³â”‚
â”‚  â”œâ”€â”€ Phase 6   â€” 7-Day Labeling Mechanism                               â”‚
â”‚  â””â”€â”€ Phase 7   â€” First Cohort: Collect â†’ Wait 7d â†’ Re-check            â”‚
â”‚                                                                         â”‚
â”‚  ğŸ§¹ M3 â€” DATA PROCESSING & FEATURE ENGINEERING              [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] â³â”‚
â”‚  â”œâ”€â”€ Phase 8   â€” Data Cleaning Pipeline                                 â”‚
â”‚  â”œâ”€â”€ Phase 9   â€” Feature Engineering                                    â”‚
â”‚  â””â”€â”€ Phase 10  â€” EDA Notebook                                           â”‚
â”‚                                                                         â”‚
â”‚  ğŸ¤– M4 â€” MODELING                                           [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] â³â”‚
â”‚  â”œâ”€â”€ Phase 11  â€” Baseline Models                                        â”‚
â”‚  â”œâ”€â”€ Phase 12  â€” Advanced Models (XGB / LGBM / CatBoost)               â”‚
â”‚  â”œâ”€â”€ Phase 13  â€” Class Imbalance Handling                               â”‚
â”‚  â””â”€â”€ Phase 14  â€” Hyperparameter Tuning (Optuna)                        â”‚
â”‚                                                                         â”‚
â”‚  ğŸ“Š M5 â€” EVALUATION & EXPLAINABILITY                        [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] â³â”‚
â”‚  â”œâ”€â”€ Phase 15  â€” Test Set Evaluation                                    â”‚
â”‚  â”œâ”€â”€ Phase 16  â€” SHAP Analysis                                          â”‚
â”‚  â””â”€â”€ Phase 17  â€” Visualization Suite                                    â”‚
â”‚                                                                         â”‚
â”‚  ğŸ“ M6 â€” REPORTING & DELIVERY                               [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] â³â”‚
â”‚  â”œâ”€â”€ Phase 18  â€” Final Analysis Report                                  â”‚
â”‚  â””â”€â”€ Phase 19  â€” Presentation / Paper Draft                             â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—ï¸ M0 â€” FOUNDATION

### Phase 0 â€” Project Architecture `fa1b082`
> commit: `chore: initialize project architecture`

- [x] KlasÃ¶r yapÄ±sÄ± oluÅŸtur (`src/`, `data/`, `artifacts/`, `configs/`, `docs/`, `tests/`, `notebooks/`, `reports/`)
- [x] Alt paketler (`src/scraping/`, `src/labeling/`, `src/features/`, `src/models/`, `src/evaluation/`, `src/utils/`, `src/pipelines/`, `src/preprocessing/`, `src/dataset/`)
- [x] Senior-grade `.gitignore` (data, artifacts, .env, __pycache__, notebooks checkpoints, IDE)
- [x] `requirements.txt` (scraping + data + ML + viz + test + quality)
- [x] `pyproject.toml` (black, ruff, pytest konfigÃ¼rasyonu)
- [x] `.env.example`
- [x] `README.md`
- [x] Branch stratejisi: `main` (stable) / `develop` (active) / `feature/*`
- [x] GitHub repo: `thefcan/dolap-sale-prediction`

### Phase 0 â€” Restructuring `2c5e63a`
> commit: `chore: restructure artifacts, data snapshots, configs & pipeline entrypoints`

- [x] `models/` â†’ `artifacts/models/` migration + `artifacts/figures/` + `artifacts/metrics/`
- [x] Cohort-bazlÄ± data yapÄ±sÄ±: `data/raw_snapshots/`, `data/labels/`, `data/interim/`, `data/processed/`
- [x] `data/README.md` â€” veri akÄ±ÅŸÄ± dokÃ¼mantasyonu
- [x] Config YAML'larÄ±: `scraping.yaml`, `features.yaml`, `model.yaml`, `pipeline.yaml`
- [x] Pipeline entrypoint iskeletleri: `scrape.py`, `label.py`, `build_dataset.py`, `train.py`, `evaluate.py`

### Phase 0.5 Part 1 â€” Experiment Tracking Foundation `11f2683`
> commit: `feat: experiment tracking foundation`

- [x] `src/utils/experiment.py` â€” `create_experiment()`, `save_metadata()`, `get_git_commit_hash()`
- [x] `src/utils/config_snapshot.py` â€” `snapshot_configs()` (YAML freeze per experiment)
- [x] `src/utils/data_version.py` â€” `compute_dataset_hash()` SHA-256 fingerprint
- [x] `src/utils/seed.py` â€” `set_global_seed()` (random, numpy, torch, PYTHONHASHSEED)
- [x] `artifacts/experiments/` dizini + `.gitignore` kuralÄ±
- [x] `configs/pipeline.yaml` gÃ¼ncelleme (`artifacts_experiments` path)

### Phase 0.5 Part 2 â€” Reproducible Training Pipeline `3cc0f6b`
> commit: `feat: reproducible training pipeline integration`

- [x] `src/utils/split.py` â€” `temporal_train_val_test_split()` (kesinlikle zaman bazlÄ±, shuffle YOK)
- [x] `src/utils/metrics.py` â€” `compute_classification_metrics()` + `save_metrics()` (JSON)
- [x] `src/utils/logger.py` â€” loguru structured logging + `experiment_id` injection
- [x] `src/pipelines/train.py` â€” tam experiment lifecycle (10 adÄ±m)
- [x] `src/utils/__init__.py` â€” tÃ¼m public API'leri re-export

### Phase 1 â€” Literature Research & Project Report âœ…
> Dosya: `docs/PROJE_RAPORU.md` (575 satÄ±r)

- [x] Google Scholar taramasÄ± â€” Dolap.com Ã¼zerine ML Ã§alÄ±ÅŸmasÄ± **YOK** (teyit edildi)
- [x] Benzer platform Ã§alÄ±ÅŸmalarÄ± (Mercari, ZOZOUSED, genel)
- [x] Ã–zgÃ¼nlÃ¼k deÄŸerlendirmesi (platform + gÃ¶rev + coÄŸrafi + metodolojik)
- [x] Platform analizi â€” URL yapÄ±sÄ±, HTML structure, Ã¼rÃ¼n sayfasÄ± veri haritasÄ±
- [x] 25+ Ã¶zellik tanÄ±mÄ± (listing, seller, engagement, derived)
- [x] 5-tier marka kademe sistemi (Budget â†’ Luxury)
- [x] Scraping mimarisi (Phase 1-2-3 diyagramÄ±)
- [x] 5 model Ã¶nerisi + deneysel tasarÄ±m
- [x] 6 deÄŸerlendirme metriÄŸi + sÄ±nÄ±f dengesizliÄŸi stratejileri
- [x] 6 haftalÄ±k zaman Ã§izelgesi
- [x] Risk analizi (7 risk + azaltma stratejileri)
- [x] 8 akademik referans

---

## ğŸŒ M1 â€” DATA COLLECTION SYSTEM

### Phase 2 â€” Dolap Site Reverse Engineering `8bacbfc`
> commit: `feat: dolap site reverse engineering`

- [x] Dolap.com `robots.txt` analizi ve uyumluluk notu
- [x] Listing URL pattern tespiti ve doÄŸrulama
  - Ã–rnek: `dolap.com/urun/{marka}-{renk}-{kategori}-{durum}-{satici}-{id}`
- [x] Kategori sayfasÄ± pagination yapÄ±sÄ±
  - Sayfa numaralama: query param (`?sayfa=N`) + SPA rendering
  - Bir sayfada ~20 ilan
- [x] ÃœrÃ¼n detay sayfasÄ± HTML structure mapping
  - Fiyat selector
  - Marka selector
  - Durum etiketi selector
  - FotoÄŸraf sayÄ±sÄ± selector
  - AÃ§Ä±klama selector
  - Beden / renk selector
  - Kargo bilgisi selector
- [x] SatÄ±cÄ± profil sayfasÄ± yapÄ±sÄ±
  - Rating/deÄŸerlendirme sayÄ±sÄ±
  - Toplam satÄ±ÅŸ
  - Hesap yaÅŸÄ± (mÃ¼mkÃ¼nse â†’ elde edilemiyor)
- [x] **"SatÄ±ldÄ±" badge detection** â€” HTML'de nasÄ±l gÃ¶rÃ¼nÃ¼yor?
  - CSS class? Text? Overlay?
  - 404 vs "SatÄ±ldÄ±" vs "KaldÄ±rÄ±ldÄ±" ayrÄ±mÄ±
- [x] JavaScript-rendered content var mÄ±? (SSR vs CSR tespiti)
  - **Cloudflare WAF** tÃ¼m HTTP client'larÄ± blokluyor (403)
  - **Selenium zorunlu** â€” real browser gerekiyor
  - Kategori sayfalarÄ±: SPA (JS render)
  - ÃœrÃ¼n detay sayfalarÄ±: SSR benzeri (HTML'de mevcut)
- [x] Dolap API endpoint keÅŸfi (network tab analizi)
  - `/api/product/{id}` ve `/rest/product/{id}` â†’ 403 bloklu
  - `public-mdc.dolap.com` â†’ DNS Ã§Ã¶zÃ¼nemiyor
- [x] `docs/DOLAP_SITE_MAP.md` â€” tÃ¼m bulgularÄ± dokÃ¼mante et (354 satÄ±r, 14 bÃ¶lÃ¼m)
- [x] Test: 3-5 farklÄ± kategoriden elle 1'er ilan parse et

### Phase 3 â€” Basic Scraper Prototype `(commit pending)`
> commit hedefi: `feat: basic scraper prototype`

- [x] `src/scraping/scraper.py` â€” Selenium-based DolapScraper sÄ±nÄ±fÄ±
  - WebDriver lifecycle (headless Chrome, anti-detection flags)
  - Cloudflare bypass (real browser rendering)
  - `crawl_category()` â†’ kategori sayfalarÄ±ndan ilan URL'leri
  - `scrape_listing()` â†’ tekil ilan detay parse
  - `scrape_listings_batch()` â†’ toplu scrape + JSONL streaming
  - `scrape_category()` â†’ end-to-end kategori pipeline
  - Random delay, retry logic, exponential backoff
- [x] `src/scraping/parsers.py` â€” 17 HTML parser fonksiyonu (~400 satÄ±r)
  - `parse_product_detail()` â†’ ana parser (20+ alan)
  - `parse_listing_urls_from_page()` â†’ kategori sayfasÄ± URL extraction
  - `extract_listing_id_from_url()` â†’ URL'den listing ID
  - Graceful error handling, `_parse_errors` tracking
- [x] Ã‡ekilecek alanlar:
  - `listing_id`, `url`, `title`, `price`, `original_price`
  - `brand`, `category`, `subcategory`
  - `size`, `color`, `condition`
  - `photo_count`, `description_length`, `description_text`, `description_word_count`
  - `seller_username`, `seller_listing_count`
  - `has_discount`, `shipping_info`, `shipping_buyer_pays`
  - `like_count`, `comment_count`
  - `is_sold`, `scraped_at`
- [x] Kategori crawler: verilen kategori slug â†’ ilan URL listesi
- [x] `src/scraping/__init__.py` â€” Public API re-exports
- [x] `src/pipelines/scrape.py` â€” Full implementation (skeleton â†’ gerÃ§ek)
  - `--cohort-id`, `--categories`, `--max-pages`, `--dry-run`, `--no-headless`
  - Cohort dizini oluÅŸturma, JSONL output, `meta.yaml` Ã¼retimi
- [ ] CSV/JSONL test scrape (~50 ilan) â†’ Phase 5'te gerÃ§ek cohort ile
- [ ] Manuel doÄŸrulama: scrape edilen 10 ilan vs site gerÃ§ek deÄŸerleri
- [ ] `notebooks/01_scraping_test.ipynb` â€” scrape sonuÃ§larÄ± inceleme

### Phase 4 â€” Anti-Ban Protection
> commit hedefi: `feat: anti-ban protection layer`
> â„¹ï¸ BazÄ± maddeler Phase 3'te DolapScraper iÃ§inde temel dÃ¼zeyde implemente edildi.

- [x] Random User-Agent rotation (10 farklÄ± UA) â€” `scraper.py` _USER_AGENTS
- [x] Random request delay (config'den: `min_seconds` / `max_seconds`) â€” `scraper.py` `_sleep()`
- [x] Exponential backoff retry logic (max 3 retry) â€” `scraper.py` `_navigate()`
- [x] Timeout handling (30s default) â€” `scraper.py` `set_page_load_timeout()`
- [ ] HTTP status code handling (429, 403, 503 â†’ backoff)
- [ ] Optional: proxy support altyapÄ±sÄ± (config'de var, implementasyon)
- [ ] Optional: cookie/session management
- [ ] Rate limiter sÄ±nÄ±fÄ±: `src/scraping/rate_limiter.py`
- [ ] Banlama tespiti: ardÄ±ÅŸÄ±k 403/429 â†’ otomatik durma + uyarÄ± logu
- [ ] Test: 200 ilan Ã§ek, ban yemeden tamamla

### Phase 5 â€” Snapshot Storage System â­
> commit hedefi: `feat: snapshot storage system`

- [ ] Her scrape Ã§alÄ±ÅŸmasÄ± = 1 cohort = 1 snapshot dosyasÄ±
- [ ] Dosya adlandÄ±rma: `data/raw_snapshots/cohort_{YYYYMMDD}/listings.jsonl`
- [ ] Snapshot **ASLA overwrite EDÄ°LMEZ** â€” append-only
- [ ] Her satÄ±r: `listing_id` + `scrape_date` + tÃ¼m alanlar
- [ ] `src/scraping/storage.py` â€” snapshot writer sÄ±nÄ±fÄ±
- [ ] `src/pipelines/scrape.py` implementasyonu (skeleton â†’ gerÃ§ek)
- [ ] Scrape Ã¶zet logu: kaÃ§ ilan, kaÃ§ kategori, kaÃ§ hata, sÃ¼re
- [ ] SQLite state tracking: hangi cohort ne zaman scrape edildi
- [ ] Ä°lk gerÃ§ek cohort scrape'i: `cohort_20260301` (~1000+ ilan)

---

## â³ M2 â€” TEMPORAL LABELING SYSTEM

> **âš ï¸ PROJENÄ°N ALTIN NOKTASI**
> Ground truth doÄŸal olarak Dolap'tan elde ediliyor â€” ama bu 7 gÃ¼nlÃ¼k
> bekleme sÃ¼resini disiplinli yÃ¶netmeyi gerektiriyor.

### Phase 6 â€” 7-Day Labeling Mechanism
> commit hedefi: `feat: temporal labeling mechanism`

- [ ] `src/labeling/status_checker.py` â€” ilan durum kontrol sÄ±nÄ±fÄ±
  - URL'yi ziyaret et
  - HTTP 404/410 â†’ `removed`
  - "SatÄ±ldÄ±" badge â†’ `sold_within_7_days = 1`
  - HÃ¢lÃ¢ aktif â†’ `sold_within_7_days = 0`
  - Sayfa parse hatasÄ± â†’ `error` (ayrÄ± kaydet)
- [ ] `src/labeling/labeler.py` â€” batch labeling orchestrator
  - Bir cohort'taki tÃ¼m ilanlarÄ± sÄ±rayla kontrol et
  - Anti-ban kurallarÄ±na uy (Phase 4'ten miras)
- [ ] Label output: `data/labels/cohort_{YYYYMMDD}.jsonl`
  - Her satÄ±r: `{listing_id, url, status, sold_within_7_days, checked_at}`
- [ ] `src/pipelines/label.py` implementasyonu (skeleton â†’ gerÃ§ek)
- [ ] Edge case'ler:
  - Ä°lan silindi ama satÄ±lmadÄ± â†’ `removed_unsold` (veri setinden Ã§Ä±kar veya ayrÄ± sÄ±nÄ±f)
  - Ä°lan fiyatÄ± deÄŸiÅŸti â†’ logla (fiyat deÄŸiÅŸimi feature olabilir)
  - Ä°lan hÃ¢lÃ¢ aktif ama 404 â†’ retry logic
- [ ] Labeling sÃ¼reci logu: `X satÄ±ldÄ± / Y aktif / Z hata`

### Phase 7 â€” First Cohort Lifecycle
> commit hedefi: `feat: first cohort labeled`

- [ ] **GÃ¼n 1:** Cohort_01 scrape (~1000+ ilan)
- [ ] **GÃ¼n 2-7:** Bekleme (isteÄŸe baÄŸlÄ±: Cohort_02 scrape baÅŸlat)
- [ ] **GÃ¼n 8:** Cohort_01 re-check â†’ labeling
- [ ] Label daÄŸÄ±lÄ±mÄ± analizi: sold vs not_sold oranÄ±
- [ ] Veri kalitesi raporu: eksik alanlar, parse hatalarÄ±
- [ ] **GÃ¼n 8+:** Cohort_02, Cohort_03... paralel devam
- [ ] Hedef: minimum 3 cohort, 3000+ etiketli ilan

---

## ğŸ§¹ M3 â€” DATA PROCESSING & FEATURE ENGINEERING

### Phase 8 â€” Data Cleaning Pipeline
> commit hedefi: `feat: data cleaning pipeline`

- [ ] `src/preprocessing/cleaner.py`
  - Duplicate detection & removal (aynÄ± `listing_id`)
  - Missing value analizi + imputation stratejisi
  - Outlier detection (fiyat, description_length)
  - Data type validation (price â†’ float, date â†’ datetime)
  - TutarsÄ±z kayÄ±tlarÄ± logla ve filtrele
- [ ] `src/dataset/merger.py`
  - Raw snapshots + labels â†’ merged interim file
  - Cohort-bazlÄ± merge: `data/interim/merged_{cohort_id}.parquet`
  - TÃ¼m cohort'larÄ± birleÅŸtir: `data/interim/merged_all.parquet`
- [ ] `src/pipelines/build_dataset.py` implementasyonu â€” cleaning step

### Phase 9 â€” Feature Engineering
> commit hedefi: `feat: feature engineering pipeline`

- [ ] `src/features/engineer.py` â€” ana feature engineering sÄ±nÄ±fÄ±
- [ ] **Ä°lan Ã¶zellikleri:**
  - `price` (ham)
  - `price_to_category_median` (fiyat / kategori medyan fiyatÄ±)
  - `photo_count`
  - `description_length` (char count)
  - `description_word_count`
  - `listing_hour` (0-23)
  - `is_weekend_listing`
  - `has_discount`
  - `shipping_buyer_pays`
- [ ] **Marka kademesi:**
  - `brand_tier` (1-5, `configs/features.yaml`'dan)
  - Bilinmeyen marka â†’ tier 0 veya median tier
- [ ] **Durum etiketi:**
  - `condition` ordinal encoding (Yeni & Etiketli=3, Yeni=2, Az KullanÄ±lmÄ±ÅŸ=1, KullanÄ±lmÄ±ÅŸ=0)
- [ ] **Kategorik encoding:**
  - `category` â†’ target encoding
  - `color` â†’ target encoding
  - `size` â†’ ordinal/target encoding
- [ ] **SatÄ±cÄ± Ã¶zellikleri:**
  - `seller_rating_count`
  - `seller_sales_count` (mÃ¼mkÃ¼nse)
- [ ] **Metin Ã¶zellikleri:**
  - `desc_has_urgency_keyword` (acil, son fiyat, indirim, fÄ±rsat, pazarlÄ±k)
- [ ] OluÅŸturulan feature'larÄ±n `configs/features.yaml` ile tutarlÄ±lÄ±k kontrolÃ¼
- [ ] Final output: `data/processed/dataset.parquet`
- [ ] Feature listesi metadata'ya kaydet

### Phase 10 â€” Exploratory Data Analysis (EDA)
> commit hedefi: `feat: EDA notebook`

- [ ] `notebooks/01_eda.ipynb`
- [ ] Temel istatistikler: satÄ±r sayÄ±sÄ±, sÃ¼tun tipleri, missing ratio
- [ ] Target daÄŸÄ±lÄ±mÄ±: `sold_within_7_days` â†’ class balance
- [ ] Fiyat daÄŸÄ±lÄ±mÄ± (histogram, boxplot, kategori bazlÄ±)
- [ ] Marka tier daÄŸÄ±lÄ±mÄ±
- [ ] Durum etiketi daÄŸÄ±lÄ±mÄ±
- [ ] FotoÄŸraf sayÄ±sÄ± vs satÄ±ÅŸ oranÄ±
- [ ] Fiyat/medyan oranÄ± vs satÄ±ÅŸ oranÄ±
- [ ] SatÄ±cÄ± deneyimi vs satÄ±ÅŸ oranÄ±
- [ ] Korelasyon matrisi (numerik features)
- [ ] Kategori bazlÄ± satÄ±ÅŸ oranlarÄ±
- [ ] Zaman bazlÄ± trendler (ilan saati, gÃ¼n)
- [ ] SÄ±nÄ±f dengesizliÄŸi analizi ve strateji Ã¶nerisi

---

## ğŸ¤– M4 â€” MODELING

### Phase 11 â€” Baseline Models
> commit hedefi: `feat: baseline models`

- [ ] `src/models/baseline.py` â€” Logistic Regression
- [ ] Logistic Regression eÄŸitimi (class_weight="balanced")
- [ ] Random Forest eÄŸitimi
- [ ] Dummy classifier (stratified) â€” alt sÄ±nÄ±r belirleme
- [ ] Val set Ã¼zerinde metrikler: AUC-ROC, F1, Precision, Recall
- [ ] Baseline sonuÃ§larÄ± â†’ experiment dizinine kaydet
- [ ] Ä°lk karÅŸÄ±laÅŸtÄ±rma tablosu

### Phase 12 â€” XGBoost Deep Dive
> commit hedefi: `feat: xgboost training`

- [ ] `src/models/tree_models.py` â€” XGBoost wrapper
- [ ] XGBoost eÄŸitimi (early stopping on val)
- [ ] Feature importance (gain, weight, cover)
- [ ] Val set karÅŸÄ±laÅŸtÄ±rmasÄ± (vs baseline)
- [ ] TÃ¼m sonuÃ§lar experiment dizinine

### Phase 13 â€” Class Imbalance Handling
> commit hedefi: `feat: class imbalance strategies`

- [ ] SMOTE deneyi (imbalanced-learn)
- [ ] Class weight deneyi (her model iÃ§in)
- [ ] Threshold tuning (F1-maximize / Youden's J)
- [ ] Undersampling deneyi
- [ ] Ä°mbalance stratejisi karÅŸÄ±laÅŸtÄ±rma tablosu
- [ ] En iyi stratejiyi seÃ§ â†’ metadata'ya kaydet

### Phase 14 â€” Hyperparameter Tuning
> commit hedefi: `feat: optuna hyperparameter tuning`

- [ ] `src/models/tuner.py` â€” Optuna objective fonksiyonlarÄ±
- [ ] XGBoost Optuna study (100 trial)
- [ ] Study visualization (parallel coordinate, importance)
- [ ] Tuned XGBoost â†’ final val score
- [ ] Tuning sonuÃ§larÄ± â†’ experiment dizinine

---

## ğŸ“Š M5 â€” EVALUATION & EXPLAINABILITY

### Phase 15 â€” Test Set Evaluation
> commit hedefi: `feat: test set evaluation`

- [ ] Final model â†’ test set prediction
- [ ] `src/evaluation/evaluator.py`
- [ ] Metrikler: AUC-ROC, F1, Precision, Recall, PR-AUC, Accuracy
- [ ] Optimal threshold on val â†’ apply on test
- [ ] Confusion matrix
- [ ] Classification report
- [ ] SonuÃ§larÄ± experiment dizinine kaydet

### Phase 16 â€” SHAP Analysis
> commit hedefi: `feat: SHAP explainability`

- [ ] `src/evaluation/shap_analysis.py`
- [ ] SHAP beeswarm plot (top 20 features)
- [ ] SHAP waterfall (tek Ã¶rnek aÃ§Ä±klama)
- [ ] SHAP dependence plots (top 3-5 feature)
- [ ] Feature importance ranking (SHAP-based vs model-based karÅŸÄ±laÅŸtÄ±rma)
- [ ] Figures â†’ `artifacts/experiments/<exp>/figures/`

### Phase 17 â€” Visualization Suite
> commit hedefi: `feat: evaluation visualization suite`

- [ ] `src/evaluation/plots.py`
- [ ] ROC curve (tÃ¼m modeller aynÄ± grafikte)
- [ ] Precision-Recall curve
- [ ] Calibration plot
- [ ] Feature importance bar chart
- [ ] Confusion matrix heatmap
- [ ] Threshold vs F1 grafiÄŸi
- [ ] TÃ¼m figÃ¼rler â†’ experiment dizinine

---

## ğŸ“ M6 â€” REPORTING & DELIVERY

### Phase 18 â€” Final Analysis Report
> commit hedefi: `feat: final analysis report`

- [ ] `reports/FINAL_REPORT.md` veya `.pdf`
- [ ] YÃ¶netici Ã¶zeti
- [ ] Veri toplama sÃ¼reci ve zorluklar
- [ ] Feature engineering kararlarÄ± ve gerekÃ§eleri
- [ ] Model karÅŸÄ±laÅŸtÄ±rma tablosu
- [ ] En iyi modelin SHAP analizi yorumu
- [ ] SÄ±nÄ±f dengesizliÄŸi Ã§Ã¶zÃ¼m karÅŸÄ±laÅŸtÄ±rmasÄ±
- [ ] Pratik Ã¶neriler: satÄ±cÄ±lara fiyatlama/ilan tavsiyeleri
- [ ] Limitasyonlar ve gelecek Ã§alÄ±ÅŸmalar
- [ ] Akademik referanslar

### Phase 19 â€” Presentation / Paper Draft
> commit hedefi: `feat: presentation`

- [ ] Sunum slaytlarÄ± (10-15 slayt)
  - Problem tanÄ±mÄ±
  - Veri toplama yaklaÅŸÄ±mÄ± (temporal labeling)
  - Feature engineering
  - Model sonuÃ§larÄ±
  - SHAP aÃ§Ä±klanabilirlik
  - SonuÃ§ ve Ã¶neriler
- [ ] (Opsiyonel) KÄ±sa makale taslaÄŸÄ±

---

## ğŸ“Š Ä°lerleme Ã–zeti

| Milestone | Durum | Tamamlanan Phase |
|-----------|-------|------------------|
| ğŸ—ï¸ M0 â€” Foundation | âœ… TamamlandÄ± | Phase 0, 0.5, 1 |
| ğŸŒ M1 â€” Data Collection | ğŸ”„ Devam Ediyor | Phase 2, 3 |
| â³ M2 â€” Temporal Labeling | â³ Bekliyor | â€” |
| ğŸ§¹ M3 â€” Data Processing | â³ Bekliyor | â€” |
| ğŸ¤– M4 â€” Modeling | â³ Bekliyor | â€” |
| ğŸ“Š M5 â€” Evaluation | â³ Bekliyor | â€” |
| ğŸ“ M6 â€” Reporting | â³ Bekliyor | â€” |

## ğŸ“Œ Commit GeÃ§miÅŸi

| # | Hash | Mesaj | Branch |
|---|------|-------|--------|
| 1 | `fa1b082` | `chore: initialize project architecture` | develop |
| 2 | `2c5e63a` | `chore: restructure artifacts, data snapshots, configs & pipeline entrypoints` | develop |
| 3 | `11f2683` | `feat: experiment tracking foundation` | develop |
| 4 | `3cc0f6b` | `feat: reproducible training pipeline integration` | develop |
| 5 | `c2f4805` | `merge: sync develop into main (Phase 0 + 0.5)` | main |
| 6 | `556c8a7` | `merge: sync develop into main (Phase 0.5 Part 2)` | main |
| 7 | `8bacbfc` | `feat: dolap site reverse engineering` | develop |
| 8 | `(pending)` | `feat: basic scraper prototype` | develop |

## ğŸ—ï¸ AltyapÄ± Envanteri

### âœ… Implementasyon Tamamlanan ModÃ¼ller
```
src/utils/
â”œâ”€â”€ experiment.py       â† create_experiment, save_metadata, get_git_commit_hash
â”œâ”€â”€ config_snapshot.py  â† snapshot_configs
â”œâ”€â”€ data_version.py     â† compute_dataset_hash, compute_file_hash
â”œâ”€â”€ seed.py             â† set_global_seed (random, numpy, torch, PYTHONHASHSEED)
â”œâ”€â”€ split.py            â† temporal_train_val_test_split (zaman bazlÄ±, shuffle YOK)
â”œâ”€â”€ metrics.py          â† compute_classification_metrics, save_metrics
â”œâ”€â”€ logger.py           â† setup_logging, get_logger (loguru + experiment_id)
â””â”€â”€ __init__.py         â† tÃ¼m public API re-export
```

### âœ… KonfigÃ¼rasyon DosyalarÄ±
```
configs/
â”œâ”€â”€ scraping.yaml       â† 12 kategori, rate limiting, labeling kurallarÄ±
â”œâ”€â”€ features.yaml       â† brand tiers, condition mapping, feature tanÄ±mlarÄ±
â””â”€â”€ model.yaml          â† 3 model config (LR, RF, XGB), seed, split oranlarÄ±, Optuna, evaluation
â””â”€â”€ pipeline.yaml       â† paths, logging, database URL, step enable/disable
```

### âœ… Scraping ModÃ¼lÃ¼ (Phase 2-3)
```
src/scraping/
â”œâ”€â”€ __init__.py         â† Public API re-exports (DolapScraper, parsers)
â”œâ”€â”€ parsers.py          â† 17 HTML parse fonksiyonu (~400 satÄ±r)
â””â”€â”€ scraper.py          â† Selenium-based DolapScraper sÄ±nÄ±fÄ± (~330 satÄ±r)
```

### â³ Ä°skelet (Skeleton) â€” Ä°mplementasyon Bekliyor
```
src/pipelines/
â”œâ”€â”€ train.py            â† âœ… TAM Ä°MPLEMENTASYON (experiment lifecycle)
â”œâ”€â”€ scrape.py           â† âœ… TAM Ä°MPLEMENTASYON (Phase 3)
â”œâ”€â”€ label.py            â† â³ Ä°skelet (Phase 6'da implement edilecek)
â”œâ”€â”€ build_dataset.py    â† â³ Ä°skelet (Phase 8-9'da implement edilecek)
â””â”€â”€ evaluate.py         â† â³ Ä°skelet (Phase 15-17'de implement edilecek)

src/labeling/           â† â³ BoÅŸ (Phase 6-7)
src/preprocessing/      â† â³ BoÅŸ (Phase 8)
src/features/           â† â³ BoÅŸ (Phase 9)
src/dataset/            â† â³ BoÅŸ (Phase 8)
src/models/             â† â³ BoÅŸ (Phase 11-14)
src/evaluation/         â† â³ BoÅŸ (Phase 15-17)
```

---

## âš¡ Sonraki AdÄ±m

> **Phase 4 â€” Anti-Ban Protection**
>
> Mevcut scraper'Ä±n rate limiting ve retry mekanizmalarÄ±nÄ±
> gÃ¼Ã§lendir. Proxy desteÄŸi, ban tespiti, session yÃ¶netimi ekle.
> ArdÄ±ndan Phase 5 (Snapshot Storage) ile ilk gerÃ§ek cohort
> scrape'ini gerÃ§ekleÅŸtir.
